{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01-policy-evaluation-solution.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"yUrdYdb9kN7x","colab_type":"code","outputId":"1f393960-b63d-484f-9058-42a1882dc27c","executionInfo":{"status":"ok","timestamp":1538046294090,"user_tz":-600,"elapsed":6239,"user":{"displayName":"Artem Golubev","photoUrl":"","userId":"13236123089665968926"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["# !python -m pip install -e git+https://github.com/star-ai/rl-environments.git#egg=rlenvs\n","# !python -m pip install gym\n","!pip install -e git+https://github.com/star-ai/rl-environments.git#egg=rlenvs\n","!pip install gym"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Obtaining rlenvs from git+https://github.com/star-ai/rl-environments.git#egg=rlenvs\n","  Updating ./src/rlenvs clone\n","Installing collected packages: rlenvs\n","  Found existing installation: rlenvs 0.1\n","    Can't uninstall 'rlenvs'. No files were found to uninstall.\n","  Running setup.py develop for rlenvs\n","Successfully installed rlenvs\n","Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.24)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0evCgEg-kH0Y","colab_type":"code","colab":{}},"source":["from IPython.core.debugger import set_trace\n","import numpy as np\n","import pprint\n","\n","# Import below can all of a sudden break\n","from src.rlenvs.rlenvs.envs.gridworld import GridworldEnv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrDI70xEkH0b","colab_type":"code","colab":{}},"source":["pp = pprint.PrettyPrinter(indent=2)\n","env = GridworldEnv()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tub2Xxs6kH0d","colab_type":"code","colab":{}},"source":["def policy_eval(policy, env, discount_factor=1.0, theta=0.00001):\n","    \"\"\"\n","    Evaluate a policy given an environment and a full description of the environment's dynamics.\n","    \n","    Args:\n","        policy: [S, A] shaped matrix representing the policy.\n","        env: OpenAI env. env.P represents the transition probabilities of the environment.\n","            env.P[s][a] is a list of transition tuples (prob, next_state, reward, done).\n","            env.nS is a number of states in the environment. \n","            env.nA is a number of actions in the environment.\n","        theta: We stop evaluation once our value function change is less than theta for all states.\n","        discount_factor: Gamma discount factor.\n","    \n","    Returns:\n","        Vector of length env.nS representing the value function.\n","    \"\"\"\n","    # Start with a random (all 0) value function\n","    V = np.zeros(env.nS)\n","    while True:\n","        delta = 0\n","        # For each state, perform a \"full backup\"\n","        for s in range(env.nS):\n","            v = 0\n","            # Look at the possible next actions\n","            for a, action_prob in enumerate(policy[s]):\n","                # For each action, look at the possible next states...\n","                for  prob, next_state, reward, done in env.P[s][a]:\n","                    # Calculate the expected value\n","                    v += action_prob * prob * (reward + discount_factor * V[next_state])\n","            # How much our value function changed (across any states)\n","            delta = max(delta, np.abs(v - V[s]))\n","            V[s] = v\n","        # Stop evaluating once our value function change is below a threshold\n","        if delta < theta:\n","            break\n","    return np.array(V)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAizPJCpkH0j","colab_type":"code","colab":{}},"source":["random_policy = np.ones([env.nS, env.nA]) / env.nA\n","v = policy_eval(random_policy, env)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDPM08oqkH0l","colab_type":"code","outputId":"d233321e-585a-4d5d-d49f-16eacfec245c","executionInfo":{"status":"ok","timestamp":1538046592571,"user_tz":-600,"elapsed":728,"user":{"displayName":"Artem Golubev","photoUrl":"","userId":"13236123089665968926"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["print(\"Value Function:\")\n","print(v)\n","print(\"\")\n","\n","print(\"Reshaped Grid Value Function:\")\n","print(v.reshape(env.shape))\n","print(\"\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Value Function:\n","[  0.         -13.99993529 -19.99990698 -21.99989761 -13.99993529\n"," -17.9999206  -19.99991379 -19.99991477 -19.99990698 -19.99991379\n"," -17.99992725 -13.99994569 -21.99989761 -19.99991477 -13.99994569\n","   0.        ]\n","\n","Reshaped Grid Value Function:\n","[[  0.         -13.99993529 -19.99990698 -21.99989761]\n"," [-13.99993529 -17.9999206  -19.99991379 -19.99991477]\n"," [-19.99990698 -19.99991379 -17.99992725 -13.99994569]\n"," [-21.99989761 -19.99991477 -13.99994569   0.        ]]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wYM5Et6okH0o","colab_type":"code","colab":{}},"source":["# Test: Make sure the evaluated policy is what we expected\n","expected_v = np.array([0, -14, -20, -22, -14, -18, -20, -20, -20, -20, -18, -14, -22, -20, -14, 0])\n","np.testing.assert_array_almost_equal(v, expected_v, decimal=2)"],"execution_count":0,"outputs":[]}]}